{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is K-Nearest Neighbors (KNN) and how does it work in both classification and regression problems?\n",
        "\n",
        "Answer:\n",
        "K-Nearest Neighbors (KNN) is a non-parametric, instance-based machine learning algorithm. It does not build an explicit model; instead, it stores all training data and makes predictions based on similarity.\n",
        "\n",
        "How it works:\n",
        "\n",
        "Choose a number of neighbors k.\n",
        "\n",
        "Compute the distance (Euclidean, Manhattan, etc.) between the new data point and all training points.\n",
        "\n",
        "Select the k closest points (neighbors).\n",
        "\n",
        "Predict:\n",
        "\n",
        "Classification: Take a majority vote among neighbors classes.\n",
        "\n",
        "Regression: Take the mean (or weighted mean) of neighbors values."
      ],
      "metadata": {
        "id": "9CdxrRWxrxdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the Curse of Dimensionality and how does it affect KNN performance?\n",
        "\n",
        "Answer:\n",
        "The Curse of Dimensionality refers to problems that occur when working with high-dimensional data.\n",
        "\n",
        "As the number of features increases:\n",
        "\n",
        "Data points become sparse.\n",
        "\n",
        "Distances lose meaning (nearest and farthest points become almost equally distant).\n",
        "\n",
        "Models require exponentially more data to generalize well.\n",
        "\n",
        "Effect on KNN:\n",
        "\n",
        "Distance metrics become unreliable.\n",
        "\n",
        "Irrelevant features can dominate the distance measure.\n",
        "\n",
        "Leads to poor classification/regression accuracy."
      ],
      "metadata": {
        "id": "y7r3Ck-or_Lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Principal Component Analysis (PCA)? How is it different from feature selection?\n",
        "\n",
        "Answer:\n",
        "Principal Component Analysis (PCA) is an unsupervised dimensionality reduction technique. It projects data onto new axes called principal components that maximize variance.\n",
        "\n",
        "Key ideas:\n",
        "\n",
        "First principal component: direction of maximum variance.\n",
        "\n",
        "Next components: orthogonal directions with decreasing variance.\n",
        "\n",
        "Helps reduce dimensionality while retaining most information.\n",
        "\n",
        "PCA vs. Feature Selection:\n",
        "\n",
        "PCA: Creates new features (linear combinations of original features).\n",
        "\n",
        "Feature selection: Keeps a subset of original features without transformation."
      ],
      "metadata": {
        "id": "PNBnhQkDt04G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are eigenvalues and eigenvectors in PCA, and why are they important?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Eigenvectors: Directions (axes) of maximum variance → principal components.\n",
        "\n",
        "Eigenvalues: Amount of variance explained along each eigenvector.\n",
        "\n",
        "Importance in PCA:\n",
        "\n",
        "Sort eigenvalues (largest to smallest) → decide how many components to keep.\n",
        "\n",
        "Eigenvectors with top eigenvalues form the reduced feature space."
      ],
      "metadata": {
        "id": "BI9184zVt2iG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: How do KNN and PCA complement each other when applied in a single pipeline?\n",
        "\n",
        "Answer:\n",
        "\n",
        "KNN relies on distances → affected by irrelevant/noisy features.\n",
        "\n",
        "PCA reduces dimensionality and noise → keeps only meaningful directions.\n",
        "\n",
        "Pipeline:\n",
        "\n",
        "Step 1: StandardScaler (normalize features).\n",
        "\n",
        "Step 2: PCA (reduce dimensionality).\n",
        "\n",
        "Step 3: KNN (classification/regression)."
      ],
      "metadata": {
        "id": "33Jvc_DLt7cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6: Train a KNN Classifier on the Wine dataset with and without feature scaling. Compare model accuracy.\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
        "                                                    random_state=42, stratify=y)\n",
        "\n",
        "# Without scaling\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "acc_no_scale = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "# With scaling\n",
        "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5))])\n",
        "pipe.fit(X_train, y_train)\n",
        "acc_scale = accuracy_score(y_test, pipe.predict(X_test))\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc_no_scale)\n",
        "print(\"Accuracy with scaling:\", acc_scale)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7_7rgb0uEcc",
        "outputId": "a83bab68-f959-4850-9c76-7d44373c9e0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.7777777777777778\n",
            "Accuracy with scaling: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Train a PCA model on the Wine dataset and print explained variance ratio.\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "pca = PCA()\n",
        "pca.fit(X_scaled)\n",
        "\n",
        "print(\"Explained variance ratio:\", np.round(pca.explained_variance_ratio_,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzL1RbYtuQuJ",
        "outputId": "0966b21e-31db-4906-8b3a-0346a53c7623"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained variance ratio: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Train a KNN Classifier on PCA-transformed dataset (top 2 components). Compare accuracy.\n",
        "\n",
        "\n",
        "pca2 = PCA(n_components=2)\n",
        "X_pca = pca2.fit_transform(X_scaled)\n",
        "\n",
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pca, y,\n",
        "                                                            test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_train_p, y_train_p)\n",
        "acc_pca2 = accuracy_score(y_test_p, knn_pca.predict(X_test_p))\n",
        "\n",
        "print(\"Accuracy with PCA (2 components):\", acc_pca2)\n",
        "print(\"Accuracy with original scaled data:\", acc_scale)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwc-8fFrvAcG",
        "outputId": "cb5e10bc-518b-4441-ffb6-38fbd54db69e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with PCA (2 components): 0.9333333333333333\n",
            "Accuracy with original scaled data: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Train a KNN Classifier with different distance metrics.\n",
        "\n",
        "\n",
        "for metric in [\"euclidean\", \"manhattan\"]:\n",
        "    model = KNeighborsClassifier(n_neighbors=5, metric=metric)\n",
        "    model.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(f\"Accuracy with {metric}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M861SbvvIAN",
        "outputId": "1c66365d-5b5e-4865-ca6c-1270a83ac7ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with euclidean: 0.7778\n",
            "Accuracy with manhattan: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: High-dimensional gene expression dataset scenario.\n",
        "\n",
        "Approach & Justification:\n",
        "\n",
        "PCA for dimensionality reduction:\n",
        "\n",
        "Reduces thousands of gene features → top components capturing 95% variance.\n",
        "\n",
        "Removes noise and redundancy.\n",
        "\n",
        "Decide number of components:\n",
        "\n",
        "Use cumulative explained variance (e.g., keep components until ≥95% variance).\n",
        "\n",
        "Apply KNN after PCA:\n",
        "\n",
        "Distance-based classification works better in reduced space.\n",
        "\n",
        "Evaluate model:\n",
        "\n",
        "Use cross-validation and test accuracy.\n",
        "\n",
        "Compare different k values for KNN.\n",
        "\n",
        "Justification to stakeholders:\n",
        "\n",
        "Reduces overfitting (small samples, many features).\n",
        "\n",
        "Improves interpretability and efficiency.\n",
        "\n",
        "Provides a robust pipeline for real-world biomedical data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGOZq2edto8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "# Synthetic high-dimensional dataset\n",
        "Xg, yg = make_classification(\n",
        "    n_samples=240, n_features=2000,\n",
        "    n_informative=50, n_classes=3, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "Xg_scaled = StandardScaler().fit_transform(Xg)\n",
        "\n",
        "# PCA (retain 95% variance)\n",
        "pca_g = PCA(n_components=0.95)\n",
        "Xg_pca = pca_g.fit_transform(Xg_scaled)\n",
        "\n",
        "# Evaluate KNN with cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "scores = cross_val_score(model, Xg_pca, yg, cv=cv)\n",
        "\n",
        "print(\"PCA components kept:\", pca_g.n_components_)\n",
        "print(\"Cross-validation accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiJmq4CStjbd",
        "outputId": "dd08b168-52e3-4e08-c46c-4062bd903dca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA components kept: 216\n",
            "Cross-validation accuracy: 0.3625\n"
          ]
        }
      ]
    }
  ]
}